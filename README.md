# EEG-Inception: A Deep Learning Model for Motor Imagery Classification

This repository contains a complete pipeline for training and evaluating the EEG-Inception neural network, a deep learning architecture designed for classifying motor imagery (MI) tasks from EEG data. The project reproduces the methodology described in the paper "An EEG-Inception Model for Motor-Imagery BCI Systems" by Lee et al., including data preprocessing, augmentation, and a subject-dependent evaluation protocol.

## Project Overview

The goal of this project is to build and validate a robust deep learning model capable of decoding a user's intentions from their brainwaves. We leverage public datasets from the BCI Competition IV (2a and 2b) to train personalized models for each subject, aiming to achieve high classification accuracy on unseen data.

The project workflow is structured into four main stages:

### 1. Data Preprocessing and Epoching

The pipeline begins by processing the raw, continuous EEG signals from the BCI Competition datasets. For each subject, the following steps are performed:

- **Load Raw Data**: Ingest .gdf files containing the recorded brain signals.
- **Channel Selection**: Remove non-EEG channels (e.g., EOG for eye movements) to focus solely on brain activity.
- **Band-Pass Filtering**: Apply a 4-40 Hz band-pass filter to the signals. This is a critical step to isolate the mu (8-13 Hz) and beta (13-30 Hz) frequency bands, which are most relevant for motor imagery, while removing low-frequency drift and high-frequency noise.
- **Epoch Extraction**: Segment the continuous signal into 3-second trials (epochs). The extraction window is precisely timed relative to the task cues presented during the experiment, ensuring each epoch captures the active motor imagery period.
- **Artifact Rejection**: Automatically discard trials that were marked as containing artifacts by experts, ensuring the model is trained on high-quality data.

### 2. Data Augmentation

To overcome the limited size of typical EEG datasets and prevent model overfitting, a specialized "noise swapping" augmentation technique is applied to the training data for each subject:

- **Noise Isolation**: For each trial, the high-frequency signal content (>100 Hz) is isolated and considered as realistic biological and sensor noise.
- **Signal-Noise Separation**: The original signal is "cleaned" by subtracting its own high-frequency noise.
- **Noise Swapping**: New, synthetic trials are generated by taking a cleaned signal from one trial and adding the noise borrowed from a different, randomly selected trial.
- **Dataset Expansion**: This process is used to significantly increase the number of training samples (e.g., 3x to 6x the original size), providing a much larger and more diverse dataset for training the deep learning model.

### 3. Model Architecture: EEG-Inception

The core of this project is the EEG-Inception model, a deep convolutional neural network inspired by Google's Inception architecture and adapted for time-series data.

- **Inception Module**: The fundamental building block extracts features in parallel using multiple convolutional filters of different lengths. This allows the model to simultaneously learn patterns from short-term, medium-term, and long-term features within the EEG signal.
- **Residual Connections**: The deep architecture (6 Inception layers) is stabilized using residual (skip) connections, a technique from ResNet that helps mitigate the vanishing gradient problem and enables effective training of deeper networks.

### 4. Subject-Dependent Training and Evaluation

Recognizing that EEG signals are highly person-specific, the project follows a rigorous subject-dependent evaluation protocol:

- **Personalized Models**: A separate, fresh model is trained and evaluated for each of the 9 subjects in the datasets.
- **Train/Test Split**: Each subject's data is split into a training set and a testing set. We use the official competition splits, where data from one session is used for training and data from a separate session (recorded on a different day) is used for testing. This provides a realistic measure of the model's generalization ability.
- **Ablation Study**: To find the optimal model configuration, an ablation study is performed by training models with varying widths ("layer depths") and evaluating their performance.
- **Performance Metrics**: The final performance is reported as the average classification accuracy across all 9 subjects, providing a robust benchmark that can be compared to state-of-the-art results. An established benchmark model, EEGNet, is also implemented to validate the data pipeline and provide a strong performance baseline.
